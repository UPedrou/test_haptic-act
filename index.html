<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Haptic-ACT">
  <meta property="og:title" content="Haptic-ACT"/>
  <meta property="og:description" content="Haptic-ACT - Pseudo Oocyte Manipulation by a Robot Using Multimodal Information and Action Chunking with Transformers"/>
  <meta property="og:url" content="https://upedrou.github.io/test_haptic-act/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="Haptic-ACT - Pseudo Oocyte Manipulation by a Robot Using Multimodal Information and Action Chunking with Transformers">
  <meta name="twitter:description" content="Haptic-ACT - Pseudo Oocyte Manipulation by a Robot Using Multimodal Information and Action Chunking with Transformers">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Haptic-ACT</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Project page for Haptic-ACT - Pseudo Oocyte Manipulation by a Robot Using Multimodal Information and Action Chunking with Transformers</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
              <a href="https://https://scholar.google.co.jp/citations?hl=ja&user=YW_5du0AAAAJ" target="_blank">Pedro Miguel Uriguen Eljuri<sup>1*</sup>,</span>
            <span class="author-block">
               Hironobu Shibata<sup>2</sup>,</span>
            <span class="author-block">
               Maeyama Katsuyoshi<sup>2</sup>,</span>
            <span class="author-block">
              Yuanyuan Jia<sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.co.jp/citations?user=dPOCLQEAAAAJ&hl=ja&oi=ao" target="_blank">Tadahiro Taniguchi<sup>1,2</sup></a></span>
            </div>

            <div class="is-size-5 publication-authors">
            <span class="author-block">
              <sup>1</sup>Kyoto University,
              <sup>2</sup>Ritsumeikan University,
              <br><span>Under Review</span>
            </span>
            <span class="eql-cntrb"><small><br><sup>*</sup>Corresponding Author</small></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Arxiv PDF link -->
              <span class="link-block">
                <a href="" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>
                    Paper (coming soon)
                  </span>
                </a>
              </span>

                    <!-- Supplementary PDF link -->
<!--                     <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

              <!-- Github link -->
              <span class="link-block">
                <a href="" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                </a>
              </span>

                <!-- ArXiv abstract Link -->
<!--                 <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span> -->
                    
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


      <!-- Teaser video-->
      <!-- <section class="hero teaser">
        <div class="container is-max-desktop">
          <div class="hero-body">
            <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
              <!-- Your video here -->
      <!--         <source src="static/videos/banner_video.mp4"
              type="video/mp4">
            </video>
            <h2 class="subtitle has-text-centered">
              Introduction video of Haptic-ACT.
            </h2>
          </div>
        </div>
      </section> -->
      <!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In this paper we introduce Haptic-ACT, an advanced robotic system for pseudo oocyte manipulation, integrating multimodal information and Action Chunking with Transformers (ACT).
            Traditional automation methods for oocyte transfer rely heavily on visual perception, often requiring human supervision due to biological variability and environmental disturbances.
            Haptic-ACT enhances ACT by incorporating haptic feedback, enabling real-time grasp failure detection and adaptive correction.
            Additionally, we introduce a 3D-printed TPU soft gripper to facilitate delicate manipulations.
            Experimental results demonstrate that Haptic-ACT improves the task success rate, robustness, and adaptability compared to conventional ACT, particularly in dynamic environments.
            These findings highlight the potential of multimodal learning in robotics for biomedical automation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Overview_3/.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Overview.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/ACT_Force_crop.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Haptic-ACT Architecture.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/robot_environment.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Hardware Environment.
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Results.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- Paper video. -->
      <h2 class="title is-3">Video Introduction</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <!-- Youtube embed code here -->
            <iframe src="https://youtu.be/tTRflwkiFno" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


    <!-- Video carousel -->
<!--     <section class="hero is-small">
      <div class="hero-body">
        <div class="container">
          <h2 class="title is-3">Another Carousel</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item item-video1">
              <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
                <!-- Your video file here -->
<!--                 <source src="static/videos/carousel1.mp4"
                type="video/mp4">
              </video>
            </div>
            <div class="item item-video2">
              <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
                <!-- Your video file here -->
<!--                 <source src="static/videos/carousel2.mp4"
                type="video/mp4">
              </video>
            </div>
            <div class="item item-video3">
              <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
                <!-- Your video file here -->
<!--                 <source src="static/videos/carousel3.mp4"
                type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
    </section> -->
    <!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{uriguen2025hapticact,
        author={Uriguen Eljuri, Pedro Miguel and Shibata, Hironobu and Maeyama, Katsuyoshi and Jia, Yuanyuan and Taniguchi, Tadahiro},
        title={Haptic-ACT - Pseudo Oocyte Manipulation by a Robot Using Multimodal Information and Action Chunking with Transformers},
        year={2025, under review}
      }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!--Laboratory Information -->
<section class="section" id="Laboratory Information">
  <div class="container is-max-desktop content">
    <h2 class="title">Laboratory Information</h2>
    <ul>
      <li><a href="https://sites.google.com/view/tanichu-lab-ku/" target="_blank" rel="noopener noreferrer">Taniguchi Laboratory (Kyoto University)</a></li>
      <li><a href="http://www.em.ci.ritsumei.ac.jp/" target="_blank" rel="noopener noreferrer">Emergent Systems Laboratory (Ritsumeikan University)</a></li>
    </ul>
  </div>
</section>
<!--End Laboratory Information -->

  <!--Acknowledgements citation -->
  <section class="section" id="Acknowledgements">
    <div class="container is-max-desktop content">
      <!-- <h2 class="title">Acknowledgements</h2> -->
      <h2 class="title">Funding</h2>
      <p>
        This work was supported by the Japan Science and Technology Agency (JST) Moonshot Research & Development Program, Grant Number JPMJMS2033.
      </p>
    </div>
  </section>
  <!--End Acknowledgements citation -->


  
  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
